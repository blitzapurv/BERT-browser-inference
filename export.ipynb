{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdTnHS5Ma0Hc"
      },
      "source": [
        "Export PyTorch model to ONNX format for serving with ONNX Runtime Web "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "text1 = \"How is Rupee values against Dollar right now?\"\n",
        "text2 = \"What is the per month overall cost per subs for FY 2023\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('irrelevant', 0.8557552695274353)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./saved_model/query_intent_model/best_model\")\n",
        "inputs = tokenizer(text1, return_tensors=\"pt\")\n",
        "\n",
        "# Pass your inputs to the model and return the `logits`\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./saved_model/query_intent_model/best_model\")\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "# Get the class with the highest probability, and use the model's `id2label` mapping to convert it to a text label\n",
        "import torch.nn.functional as F\n",
        "\n",
        "probabilities = F.softmax(logits, dim=1)\n",
        "predicted_class_id = logits.argmax().item()\n",
        "model.config.id2label[predicted_class_id], probabilities.max().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gw5w-O0YCpbm"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import transformers.convert_graph_to_onnx as onnx_convert\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e46GMI9FGYV_"
      },
      "outputs": [],
      "source": [
        "pipeline = transformers.pipeline(\"text-classification\",model=model,tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KT-lBe5hHD0U"
      },
      "outputs": [],
      "source": [
        "model = model.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lbYsOZheCwTu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using framework PyTorch: 2.4.0\n",
            "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found output output_0 with shape: {0: 'batch'}\n",
            "Ensuring inputs are in correct order\n",
            "position_ids is not present in the generated input list.\n",
            "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"
          ]
        }
      ],
      "source": [
        "onnx_convert.convert_pytorch(pipeline, opset=11, output=Path(\"./public/saved_onnx/classifier.onnx\"), use_external_format=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IB_nkkDQ7OO2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        }
      ],
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "quantize_dynamic(\"./public/saved_onnx/classifier.onnx\", \"./public/saved_onnx/classifier_int8.onnx\", \n",
        "                 weight_type=QuantType.QUInt8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyLlyMMoa-E9"
      },
      "source": [
        "Evaluate accuracy using ONNX-Runtime inference - validate PyTorch inference versus ONNX-Runtime "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "64GP3FbC3Puz"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as ort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ojSj8awa3Rd6"
      },
      "outputs": [],
      "source": [
        "session = ort.InferenceSession(\"./public/saved_onnx/classifier.onnx\")\n",
        "session_int8 = ort.InferenceSession(\"./public/saved_onnx/classifier_int8.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OeLLbPWl36Xt"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61fa4709cfeb4b1bb7e63bf39251138b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c305a5783af446e09981c7b444491b07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "intent_data = DatasetDict.load_from_disk('./data/intent_data')\n",
        "\n",
        "def map_labels(example):\n",
        "    if example[\"label\"] == \"irrelevant\":\n",
        "        example[\"label\"] = 0\n",
        "    elif example[\"label\"] == \"relevant\":\n",
        "        example[\"label\"] = 1\n",
        "    return example\n",
        "\n",
        "intent_data = intent_data.map(map_labels)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=True, max_length=512, truncation=True)\n",
        "\n",
        "tokenized_intent_data = intent_data.map(preprocess_function, batched=True)\n",
        "\n",
        "full_train_dataset = tokenized_intent_data[\"train\"]\n",
        "full_eval_dataset = tokenized_intent_data[\"test\"]\n",
        "# reduced_eval_dataset = full_eval_dataset.select(range(500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vRM83eOd3Y7M"
      },
      "outputs": [],
      "source": [
        "input_feed = {\n",
        "    \"input_ids\": np.array(full_eval_dataset['input_ids']),\n",
        "    \"attention_mask\": np.array(full_eval_dataset['attention_mask']),\n",
        "    \"token_type_ids\": np.array(full_eval_dataset['token_type_ids'])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1w5QMJSm4GW1"
      },
      "outputs": [],
      "source": [
        "out = session.run(input_feed=input_feed,output_names=['output_0'])[0]\n",
        "out_int8 = session_int8.run(input_feed=input_feed,output_names=['output_0'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YC9E5iIu4W4U"
      },
      "outputs": [],
      "source": [
        "predictions = np.argmax(out, axis=-1)\n",
        "predictions_int8 = np.argmax(out_int8, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_30694/3366162530.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"accuracy\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12c5d98e125f48358f33127ee7f45ccf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3LmHcyK4ndB",
        "outputId": "72162b8d-01a2-498c-96ca-8360ef26af8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 1.0}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=predictions, references=full_eval_dataset['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FznKYHhb56Dv",
        "outputId": "5cc77516-3a19-4b77-8df5-c36db68c98dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 1.0}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=predictions_int8, references=full_eval_dataset['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TrainEmotions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
